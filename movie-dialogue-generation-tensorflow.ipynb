{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dialogues_path = \"./data/movie_lines.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_TOKEN = \"<s>\"\n",
    "EOS_TOKEN = \"</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_lines = list()\n",
    "with open(dialogues_path) as dialogues_file:\n",
    "    for line in dialogues_file:\n",
    "        line = line.strip().lower()\n",
    "        split_line = line.split(' +++$+++ ')\n",
    "        dialogue_lines.append(SOS_TOKEN + \" \" + split_line[4] + \" \" + EOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> they do not! </s>',\n",
       " '<s> they do to! </s>',\n",
       " '<s> i hope so. </s>',\n",
       " '<s> she okay? </s>',\n",
       " \"<s> let's go. </s>\",\n",
       " '<s> wow </s>',\n",
       " \"<s> okay -- you're gonna need to learn how to lie. </s>\",\n",
       " '<s> no </s>',\n",
       " '<s> i\\'m kidding.  you know how sometimes you just become this \"persona\"?  and you don\\'t know how to quit? </s>',\n",
       " '<s> like my fear of wearing pastels? </s>']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get language stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequences(dialogue_lines):\n",
    "    \n",
    "    word_to_index_map = {SOS_TOKEN: 1, EOS_TOKEN: 2}\n",
    "    index_to_word_map = {1: SOS_TOKEN, 2: EOS_TOKEN}\n",
    "    index = 3\n",
    "    \n",
    "    dialogue_sequences = list()\n",
    "    \n",
    "    for line in dialogue_lines:\n",
    "        dialogue_sequence = list()\n",
    "        tokens = word_tokenize(line)\n",
    "        for token in tokens:\n",
    "            if token in word_to_index_map:\n",
    "                dialogue_sequence.append(word_to_index_map[token])\n",
    "            else:\n",
    "                word_to_index_map[token] = index\n",
    "                index_to_word_map[index] = token\n",
    "                dialogue_sequence.append(index)\n",
    "                index += 1\n",
    "        dialogue_sequences.append(dialogue_sequence)\n",
    "                \n",
    "    return dialogue_sequences, word_to_index_map, index_to_word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences, word_to_index_map, index_to_word_map = text_to_sequences(dialogue_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_sequences = tf.convert_to_tensor(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_index_map, index_to_word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_index_map)\n",
    "EMBEDDING_SIZE = 50\n",
    "LSTM_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(object):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
