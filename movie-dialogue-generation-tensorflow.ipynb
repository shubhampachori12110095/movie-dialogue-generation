{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dialogues_path = \"./data/movie_lines.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = \"</s>\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dialogue_lines = list()\n",
    "with open(dialogues_path) as dialogues_file:\n",
    "    for line in dialogues_file:\n",
    "        line = line.strip().lower()\n",
    "        split_line = line.split(' +++$+++ ')\n",
    "        dialogue_lines.append(split_line[4] + \" \" + EOS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> they do not! </s>',\n",
       " '<s> they do to! </s>',\n",
       " '<s> i hope so. </s>',\n",
       " '<s> she okay? </s>',\n",
       " \"<s> let's go. </s>\",\n",
       " '<s> wow </s>',\n",
       " \"<s> okay -- you're gonna need to learn how to lie. </s>\",\n",
       " '<s> no </s>',\n",
       " '<s> i\\'m kidding.  you know how sometimes you just become this \"persona\"?  and you don\\'t know how to quit? </s>',\n",
       " '<s> like my fear of wearing pastels? </s>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "source": [
    "dialogue_lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get language stats"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 80,
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 81,
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_sequences(dialogue_lines):\n",
    "    \n",
    "    word_to_index_map = {EOS_TOKEN: 1}\n",
    "    index_to_word_map = {1: EOS_TOKEN}\n",
    "    index = 3\n",
    "    max_sequence_length = 0\n",
    "    \n",
    "    dialogue_sequences = list()\n",
    "    \n",
    "    for line in dialogue_lines:\n",
    "        dialogue_sequence = list()\n",
    "        tokens = line.split()\n",
    "        for token in tokens:\n",
    "            if token in word_to_index_map:\n",
    "                dialogue_sequence.append(word_to_index_map[token])\n",
    "            else:\n",
    "                word_to_index_map[token] = index\n",
    "                index_to_word_map[index] = token\n",
    "                dialogue_sequence.append(index)\n",
    "                index += 1\n",
<<<<<<< HEAD
=======
    "        \n",
    "        if max_sequence_length < len(dialogue_sequence):\n",
    "            max_sequence_length = len(dialogue_sequence)\n",
    "        \n",
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
    "        dialogue_sequences.append(np.asarray(dialogue_sequence))\n",
    "                \n",
    "    return np.asarray(dialogue_sequences), word_to_index_map, index_to_word_map, max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, word_to_index_map, index_to_word_map, max_sequence_length = text_to_sequences(dialogue_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
=======
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "outputs": [],
   "source": [
    "padded_sequences = list()\n",
    "for dialogue_sequence in sequences:\n",
    "    padded_sequence = \\\n",
    "        np.concatenate((dialogue_sequence, \n",
    "                        np.zeros(max_sequence_length - len(dialogue_sequence))))\n",
    "    padded_sequence = tf.convert_to_tensor(padded_sequence, dtype=tf.int32)\n",
    "    padded_sequences.append(padded_sequence)\n",
    "    \n",
    "padded_sequences = tf.convert_to_tensor(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sequences), sequences[0].shape)"
=======
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(57)])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.shape"
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "MAX_SEQUENCE_LENGTH = max([len(sequence) for sequence in sequences])\n",
    "print(MAX_SEQUENCE_LENGTH)"
=======
    "padded_sequences.dtype"
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 117,
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_to_index_map, index_to_word_map"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
=======
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_to_index_map)\n",
    "print(\"VOCAB_SIZE: \" + str(VOCAB_SIZE))\n",
    "EMBEDDING_SIZE = 50"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
=======
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "source": [
    "## Build computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the computational graph in Tensorflow"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Initialize input placeholders\n",
    "input_text = tf.placeholder(tf.int32, [100, None, EMBEDDING_SIZE], name='input')\n",
    "targets = tf.placeholder(tf.int32, [100, None, EMBEDDING_SIZE], name='targets')\n",
    "print(input_text)\n",
    "print(targets)\n",
    "\n",
    "input_text_shape = tf.shape(input_text)\n",
    "\n",
    "    \n",
    "# Build the RNN cell\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units=128)\n",
    "drop_cell = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=0.75)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([drop_cell] * 1)\n",
    "\n",
    "# Set the initial state\n",
    "# initial_state = cell.zero_state(input_text_shape[0], tf.float32)\n",
    "# initial_state = tf.identity(initial_state, name='initial_state')\n",
    "\n",
    "# Create word embedding as input to RNN\n",
    "# embed = tf.contrib.layers.embed_sequence(input_text, VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "# print(embed)\n",
    "\n",
    "# Build RNN\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, input_text, dtype=tf.float32)\n",
    "final_state = tf.identity(final_state, name='final_state')\n",
    "print(outputs)\n",
    "print(final_state)\n",
    "\n",
    "# Take RNN output and make logits\n",
    "logits = tf.contrib.layers.fully_connected(outputs, VOCAB_SIZE, activation_fn=None)\n",
    "print(logits)\n",
    "\n",
    "# Calculate the probability of generating each word\n",
    "# probs = tf.nn.softmax(logits, name='probs')\n",
    "probs = tf.contrib.seq2seq.hardmax(logits, name='probs')\n",
    "\n",
    "# Define loss function\n",
    "cost = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([input_text_shape[0], input_text_shape[1]]))\n",
    "\n",
    "# Learning rate optimizer\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "\n",
    "# Gradient clipping to avoid exploding gradients\n",
    "gradients = optimizer.compute_gradients(cost)\n",
    "capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "train_op = optimizer.apply_gradients(capped_gradients)"
=======
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import BasicLSTMCell, static_rnn\n",
    "from tensorflow.contrib.layers import embed_sequence"
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "#         for i in range(len(sequences)):\n",
    "        feed_dict = {\n",
    "            input_text: np.asarray(sequences).reshape(-1, 1),\n",
    "            targets: np.asarray(sequences).reshape(-1, 1)\n",
    "        }\n",
    "        train_loss, state, _ = sess.run([cost, train_op], feed_dict)\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            print('train_loss: ', train_loss)"
=======
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 57, 50)\n",
      "(100, 50) 57\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input graph and Layer graph are not the same: Tensor(\"unstack_12:0\", shape=(100, 50), dtype=float32) is not from the passed-in graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/v2john/.env/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/v2john/.env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   4264\u001b[0m         raise ValueError(\n\u001b[0;32m-> 4265\u001b[0;31m             \"%s is not from the passed-in graph.\" % graph_element)\n\u001b[0m\u001b[1;32m   4266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"unstack_12:0\", shape=(100, 50), dtype=float32) is not from the passed-in graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-fdfc77b86018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlstm_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/v2john/.env/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m   1235\u001b[0m             state_size=cell.state_size)\n\u001b[1;32m   1236\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/v2john/.env/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mvarscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       \u001b[0;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m       \u001b[0;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/v2john/.env/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    178\u001b[0m       with vs.variable_scope(vs.get_variable_scope(),\n\u001b[1;32m    179\u001b[0m                              custom_getter=self._rnn_get_variable):\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/v2john/.env/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input graph and Layer graph are not the same: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     with vs.variable_scope(self._scope,\n",
      "\u001b[0;31mValueError\u001b[0m: Input graph and Layer graph are not the same: Tensor(\"unstack_12:0\", shape=(100, 50), dtype=float32) is not from the passed-in graph."
     ]
    }
   ],
   "source": [
    "x = embed_sequence(padded_sequences, vocab_size=VOCAB_SIZE, embed_dim=EMBEDDING_SIZE)\n",
    "print(x.shape)\n",
    "\n",
    "x = tf.unstack(x, max_sequence_length, 1)\n",
    "print(x[0].shape, len(x))\n",
    "\n",
    "lstm_cell = BasicLSTMCell(128)\n",
    "outputs, states = static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "print(outputs.shape, states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define loss and optimizer\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=encoded, labels=y))\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# # Evaluate model\n",
    "# correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# # Initializing the variables\n",
    "# init = tf.global_variables_initializer()"
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
<<<<<<< HEAD
=======
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc)\n",
    "        step += 1\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print \"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
>>>>>>> 4f0184dbaedb1a1ab2840150e3041620a284ae40
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": ".pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
